name: Reqs2tests evaluation
run-name: ${{ github.ref_name }} is testing reqs2tests
on:
  workflow_dispatch:
    inputs:
      env-set:
        type: choice
        options:
          - sanity
          - piinnovo
          - atg-customer
        description: 'Select the environment set to run the tests'
        required: false
        default: 'sanity'
      max-cost:
        description: 'Maximum cost of the tests (positive float, 0 for unlimited)'
        required: false
        default: '0'
      model-config:
        description: 'The config name of the model to use for the evaluation'
        required: false
        default: 'gpt-4o-azure'
        type: choice
        options:
          - claude-3-7-sonnet
          - gpt-4.1-mini
          - gpt-4o-azure
          - gpt-o3mini-azure
          - o3-mini
          - o4-mini
          - qwen3-30b
          - qwq
      reasoning-model-config:
        description: 'The config name of the reasoning model to use for the evaluation'
        required: false
        default: 'gpt-o3mini-azure'
        type: choice
        options:
          - claude-3-7-sonnet
          - gpt-4.1-mini
          - gpt-4o-azure
          - gpt-o3mini-azure
          - o3-mini
          - o4-mini
          - qwen3-30b
          - qwq
      model-params-override:
        description: 'The model parameters to override (param1=value1;param2=value2;...)'
        required: false
      reasoning-model-params-override:
        description: 'The reasoning model parameters to override (param1=value1;param2=value2;...)'
        required: false
      no-proxy-extension:
        description: 'The no_proxy extension to add (comma separated list)'
        required: false
        default: '10.180.44.4'
      batched-mode:
        type: boolean
        description: 'Enable batched mode for the evaluation'
        required: false
        default: true
      individual-decomposition:
        type: boolean
        description: 'Enable individual decomposition for the evaluation'
        required: false
        default: false
env:
  NODE_EXTRA_CA_CERTS: /etc/ssl/certs/ca-certificates.crt
  REQUESTS_CA_BUNDLE: /etc/ssl/certs/ca-certificates.crt
  VCAST_USER_HOME: /home/vcast_user
jobs:
  reqs2tests_eval:
    timeout-minutes: 1440
    permissions: write-all
    runs-on: [self-hosted, reqs2tests, Linux]
    env:
      VECTORCAST_DIR: /vcast/${{ vars.VCAST_VERSION }}
      VECTOR_LICENSE_FILE: /vcast/vector-license.lic
      ENV_SET_NAME: ${{ github.event.inputs.env-set }}
      MAX_COST: ${{ github.event.inputs.max-cost }}
      PIINNOVO_SRC: "https://rds-vtc-docker-dev-local.vegistry.vg.vector.int/artifactory/rds-build-packages-generic-dev-local/code2reqs2tests/piinnovo-source.tar.gz"
      HALLA_SRC: "https://rds-vtc-docker-dev-local.vegistry.vg.vector.int/artifactory/rds-build-packages-generic-dev-local/code2reqs2tests/halla-modmgr4a-source.tar.gz"
      AUTOREQ_MLFLOW_SERVER: ${{ vars.AUTOREQ_MLFLOW_SERVER }}
      REQ2TESTS_MODEL: ${{ github.event.inputs.model-config }}
      REQ2TESTS_REASONING_MODEL: ${{ github.event.inputs.reasoning-model-config }}
      REQ2TESTS_MODELS_PATH: /llm_configs
      BATCHED_MODE: ${{ github.event.inputs.batched-mode }}
      INDIVIDUAL_DECOMPOSITION: ${{ github.event.inputs.individual-decomposition }}

    container:
      image: rds-vtc-docker-dev-local.vegistry.vg.vector.int/vcast/reqs2tests_ci:latest
      options: --user vcast_user --mount type=bind,source=${{ vars.VCAST_RELEASES_PATH }},target=/vcast --mount type=bind,source=${{ vars.LLM_CONFIGS_PATH }},target=/llm_configs

    steps:
      - name: Environment setup
        shell: bash
        run: |
          function parse_and_set_env_vars() {
            local model_name=$1
            local params_string=$2
            
            if [[ -n "$params_string" ]]; then
              IFS=';' read -ra PARAMS <<< "$params_string"
              for param in "${PARAMS[@]}"; do
                if [[ "$param" == *"="* ]]; then
                  KEY=$(echo "$param" | cut -d'=' -f1)
                  VALUE=$(echo "$param" | cut -d'=' -f2-)
                  echo "Overriding parameter $KEY with value $VALUE for $model_name"
                  ENV_VAR="${model_name^^}_${KEY}"
                  echo "$ENV_VAR=$VALUE" >> $GITHUB_ENV
                fi
              done
            fi
          }
          
          declare -A model_configs=(
            ["${REQ2TESTS_MODEL}"]="${{ github.event.inputs.model-params-override }}"
            ["${REQ2TESTS_REASONING_MODEL}"]="${{ github.event.inputs.reasoning-model-params-override }}"
          )
          
          for model_name in "${!model_configs[@]}"; do
            parse_and_set_env_vars "$model_name" "${model_configs[$model_name]}"
          done
          
          # adjusting no-proxy
          no_proxy_extension="${{ github.event.inputs.no-proxy-extension }}"
          if [[ -n "$no_proxy_extension" ]]; then
            echo "no_proxy=$no_proxy,$no_proxy_extension" >> $GITHUB_ENV
          fi
      - name: Check out repository
        id: checkout
        uses: actions/checkout@v4
        continue-on-error: true

      - name: Wait before retry
        id: should-retry-checkout
        if: failure()
        continue-on-error: true
        run: |
          sleep 10
          exit 1

      - name: Check out repository (retry)
        if: failure()
        uses: actions/checkout@v4

      - name: Virtual environment restore from cache
        uses: actions/cache/restore@v4
        id: cache-venv-restore
        with:
          path: ${{ env.VCAST_USER_HOME }}/.venv/
          key: ${{ runner.os }}-venv-${{ hashFiles('./setup.py') }}-${{ hashFiles('./autoreq/**/*') }}

      - name: Setup Python virtual environment
        if: steps.cache-venv-restore.outputs.cache-hit != 'true'
        run: |
          python3.10 -m venv ${{ env.VCAST_USER_HOME }}/.venv
          source ${{ env.VCAST_USER_HOME }}/.venv/bin/activate
          pip install --no-cache --upgrade pip
          pip install --no-cache -e .[dev]
          deactivate
        shell: bash

      - name: Virtual environment save cache
        if: steps.cache-venv-restore.outputs.cache-hit != 'true'
        uses: actions/cache/save@v4
        with:
          path: ${{ env.VCAST_USER_HOME }}/.venv/
          key: ${{ runner.os }}-venv-${{ hashFiles('./setup.py') }}-${{ hashFiles('./autoreq/**/*') }}

      - name: Reqs2tests evaluation
        run: |
          ./ci/reqs2tests_eval.sh
        shell: bash

      - name: Upload reports and show summary
        if: always()
        run: |
          echo "### Info" >> $GITHUB_STEP_SUMMARY
          echo "**Environment set:** ${{ env.ENV_SET_NAME }}" >> $GITHUB_STEP_SUMMARY
          echo "**Max cost:** ${{ env.MAX_COST }}" >> $GITHUB_STEP_SUMMARY
          echo "**Model config name:** ${{ env.REQ2TESTS_MODEL }}" >> $GITHUB_STEP_SUMMARY
          echo "**Model parameters override:** ${{ github.event.inputs.model-params-override }}" >> $GITHUB_STEP_SUMMARY
          echo "**Reasoning model config name:** ${{ env.REQ2TESTS_REASONING_MODEL }}" >> $GITHUB_STEP_SUMMARY
          echo "**Reasoning model parameters override:** ${{ github.event.inputs.reasoning-model-params-override }}" >> $GITHUB_STEP_SUMMARY
          echo "**Batched mode:** ${{ env.BATCHED_MODE }}" >> $GITHUB_STEP_SUMMARY
          echo "**Individual decomposition:** ${{ env.INDIVIDUAL_DECOMPOSITION }}" >> $GITHUB_STEP_SUMMARY
          
          CODE=0
          source $VCAST_USER_HOME/.venv/bin/activate
          python evaluation/create_report.py --input ${{ env.VCAST_USER_HOME }}/.envs/r2t_eval_results --output ${{ env.VCAST_USER_HOME }}/.envs/report.html
          markdownify ${{ env.VCAST_USER_HOME }}/.envs/report.html > ${{ env.VCAST_USER_HOME }}/.envs/results.md
          python ./ci/run_evaluation.py ${{ env.VCAST_USER_HOME }}/.envs/r2t_eval_results
          CODE=$?
          deactivate
          
          echo '## Failures' >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          if [[ -f requirements_check_errors.txt ]] ; then
            echo "Errors found in requirements_check_errors.txt"
            cat requirements_check_errors.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            CODE=1
          else
            echo 'No errors found' >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
          
          COMMIT_DATE=$(git log -1 --format=%cd --date=format:%Y-%m-%dT%H:%M:%S)
          BASE_ARTIFACTORY_URL="https://artifactory.vi.vector.int:443/artifactory/rds-build-packages-generic-dev/code2reqs2tests/tests-results/${{ github.ref_name }}/$COMMIT_DATE-${{ github.sha }}/${{ env.ENV_SET_NAME }}"
          REPORT_URL=$BASE_ARTIFACTORY_URL/report.html
          RESULTS_URL=$BASE_ARTIFACTORY_URL/r2t_eval_results/
          curl -H "X-JFrog-Art-Api:${{ secrets.ARTIFACTORY_TOKEN }}" -X PUT $REPORT_URL -T ${{ env.VCAST_USER_HOME }}/.envs/report.html
          cd ${{ env.VCAST_USER_HOME }}/.envs/r2t_eval_results
          tar -cvzf ../to_upload.tar.gz . > /dev/null
          cd ..
          curl -H "X-Explode-Archive: true" -H "X-JFrog-Art-Api:${{ secrets.ARTIFACTORY_TOKEN }}" -X PUT $RESULTS_URL -T ./to_upload.tar.gz
          
          echo '## HTML Report' >> $GITHUB_STEP_SUMMARY
          echo "[See report]($REPORT_URL)" >> $GITHUB_STEP_SUMMARY
          echo "## Results folder" >> $GITHUB_STEP_SUMMARY
          echo "[Results folder]($RESULTS_URL)" >> $GITHUB_STEP_SUMMARY
          
          echo "## Markdown results" >> $GITHUB_STEP_SUMMARY
          cat ${{ env.VCAST_USER_HOME }}/.envs/results.md >> $GITHUB_STEP_SUMMARY
          
          exit $CODE
        shell: bash